part-2 : https://www.tensorflow.org/versions/master/tutorials/image_retraining





#Using the Retrained Model:
The script will write out a version of the Inception v3 network with a final layer retrained to your categories to /tmp/output_graph.pb, 
and a text file containing the labels to /tmp/output_labels.txt. 

 Since you've replaced the top layer, you will need to specify the new name in the script, for example with the flag --
 output_layer=final_result if you're using label_image.


'''Here's an example of how to build and run the label_image example with your retrained graphs:'''

bazel build tensorflow/examples/label_image:label_image && \
bazel-bin/tensorflow/examples/label_image/label_image \
--graph=/tmp/output_graph.pb --labels=/tmp/output_labels.txt \
--output_layer=final_result \
--image=$HOME/flower_photos/daisy/21652746_cc379e0eea_m.jpg

You should see a list of flower labels, in most cases with daisy on top (though each retrained model may be slightly different). You can 
replace the --image parameter with your own images to try those out, and use the C++ code as a template to integrate with your own 
applications.
If you'd like to use the retrained model in a Python program this example from @eldor4do shows what you'll need to do.
https://github.com/eldor4do/TensorFlow-Examples/blob/master/retraining-example.py





#Training on Your Own Categories:
If you've managed to get the script working on the flower example images, you can start looking at teaching it to recognize categories 
you care about instead. In theory all you'll need to do is point it at a set of sub-folders, each named after one of your categories and 
containing only images from that category. 

If you do that and pass the root folder of the subdirectories as the argument to --image_dir, 
the script should train just like it did for the flowers.


In practice it may take some work to get the accuracy you want. I'll try to guide you through some of the common problems you might 
encounter below.
..TODO.. REMAINING







